# The General Person Algorithm

**Research Phase 5** | 2026-01-22
**Goal**: Synthesize multi-model collaboration research into a unified framework for building an iterative, self-learning engine

---

## Executive Summary

This document presents the **General Person Algorithm (GPA)** - a unified framework for how AI agents can think, act, and learn. It emerged from 5 phases of multi-model collaboration research and synthesizes three interconnected pieces:

1. **Problem Solving** (Sophisticated Minds) - How to think deeply about hard problems
2. **Workflow Execution** (ISLE) - How to actually do things
3. **Learning** (Rich Learning Capture) - How to get better over time

The key insight: **These are not separate systems but interconnected layers of a single cognitive architecture**.

---

## The Core Framework

### The Three Pieces

| Piece | Purpose | Core Principle |
|-------|---------|----------------|
| **Problem Solving** | Decide HOW to approach | Coordinates *beliefs* about the best approach |
| **Workflow Execution** | DO the work | Coordinates *actions* on shared artifacts |
| **Learning** | Get BETTER over time | Converts experience into reusable knowledge |

### Unified Architecture

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                          GENERAL PERSON ALGORITHM                                        │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                          │
│  ╔═══════════════════════════════════════════════════════════════════════════════════╗  │
│  ║                           PERSISTENT MEMORY LAYER                                  ║  │
│  ║  (Rich Learning Capture)                                                          ║  │
│  ║                                                                                    ║  │
│  ║  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐          ║  │
│  ║  │ LESSON CARDS │  │ CAUSAL       │  │ TRANSACTIVE  │  │ SKILL        │          ║  │
│  ║  │              │  │ MODELS       │  │ MEMORY       │  │ PROFILES     │          ║  │
│  ║  │ • What       │  │              │  │              │  │              │          ║  │
│  ║  │ • Why        │  │ • Root cause │  │ • Who knows  │  │ • Agent caps │          ║  │
│  ║  │ • When       │  │ • Effects    │  │   what       │  │ • Beta dist  │          ║  │
│  ║  │ • Confidence │  │ • Boundary   │  │ • Routing    │  │ • Performance│          ║  │
│  ║  └──────────────┘  └──────────────┘  └──────────────┘  └──────────────┘          ║  │
│  ╚═══════════════════════════════════════════════════════════════════════════════════╝  │
│                                    ▲           │                                         │
│                    Retrieve        │           │        Store                            │
│                                    │           ▼                                         │
│  ╔═══════════════════════════════════════════════════════════════════════════════════╗  │
│  ║                           EXECUTION ENGINE (ISLE)                                  ║  │
│  ╠═══════════════════════════════════════════════════════════════════════════════════╣  │
│  ║                                                                                    ║  │
│  ║  ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐║  │
│  ║  │ SENSE  │───►│ ORIENT │───►│ DECIDE │───►│  ACT   │───►│REFLECT │───►│ ADAPT  │║  │
│  ║  │        │    │        │    │        │    │        │    │        │    │        │║  │
│  ║  │Perceive│    │Retrieve│    │Choose  │    │Execute │    │Observe │    │Update  │║  │
│  ║  │input   │    │lessons │    │approach│    │decision│    │outcome │    │behavior│║  │
│  ║  └────────┘    └───┬────┘    └───┬────┘    └────────┘    └───┬────┘    └────────┘║  │
│  ║                    │             │                           │                    ║  │
│  ║                    │  TRIGGER?   │                           │                    ║  │
│  ║                    │             ▼                           │                    ║  │
│  ║                    │    ╔════════════════════════════╗      │                    ║  │
│  ║                    └───►║  SOPHISTICATED MINDS MODE  ║◄─────┘                    ║  │
│  ║                         ║  ════════════════════════  ║  (on failure)             ║  │
│  ║                         ║                            ║                            ║  │
│  ║                         ║  1. CRYSTALLIZE            ║                            ║  │
│  ║                         ║     What IS the problem?   ║                            ║  │
│  ║                         ║                            ║                            ║  │
│  ║                         ║  2. DIVERGENT EXPLORE      ║                            ║  │
│  ║                         ║     Fork-Merge, Devil's    ║                            ║  │
│  ║                         ║     Advocate, Frameworks   ║                            ║  │
│  ║                         ║                            ║                            ║  │
│  ║                         ║  3. CROSS-POLLINATE        ║                            ║  │
│  ║                         ║     Compare, combine       ║                            ║  │
│  ║                         ║                            ║                            ║  │
│  ║                         ║  4. SYNTHESIZE             ║                            ║  │
│  ║                         ║     Tribunal, unified      ║                            ║  │
│  ║                         ╚════════════════════════════╝                            ║  │
│  ╚═══════════════════════════════════════════════════════════════════════════════════╝  │
│                                                                                          │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## Piece 1: Problem Solving (Sophisticated Minds)

### What It Does

Sophisticated Minds is a **deep thinking mode** that's invoked when problems are novel, complex, or high-stakes. Unlike quick pattern-matching, it:

- Spends ~30 minutes exploring thoroughly
- Applies multiple thinking frameworks in parallel
- Tests ideas against criteria
- Reflects and iterates
- Returns with a well-reasoned answer

### Why It's Needed

From Phase 2 research: "The winner depends on whether errors are isolated vs systemic." The type of thinking should match the type of problem.

| Problem Type | Thinking Needed | Why |
|--------------|-----------------|-----|
| Known pattern | Quick recall | Speed matters, answer is known |
| Novel problem | Divergent exploration | Unknown territory needs breadth |
| High-stakes decision | Adversarial testing | Errors are expensive |
| Multiple valid approaches | Fork-merge exploration | Need to compare fairly |

### The Thinking Frameworks

| Framework | What It Reveals | When It Shines |
|-----------|-----------------|----------------|
| **First Principles** | Hidden assumptions, unnecessary constraints | When the conventional approach feels "stuck" |
| **Inversion** | Failure modes, overlooked risks | Complex systems with many ways to fail |
| **Dialectical** | Synthesis from opposing views | When valid but conflicting approaches exist |
| **Devil's Advocate** | Weaknesses in proposals | After initial synthesis needs stress-testing |
| **Fork-Merge** | Parallel path comparison | When choices are mutually exclusive |
| **Tribunal** | Evidence-based resolution | When models disagree on facts |

### The Process

```
Phase 1: CRYSTALLIZE (5 min)
├── What is actually being asked?
├── What would a great answer look like?
└── What are the success criteria?

Phase 2: DIVERGENT EXPLORE (15 min)
├── Approach 1: First principles analysis
├── Approach 2: Inversion - what would fail?
├── Approach 3: Analogy from other domains
├── Approach 4: Constraint relaxation
└── Approach 5: Steelman the opposite

Phase 3: CROSS-POLLINATE (5 min)
├── What does Approach 1 reveal that 2 missed?
├── Where do approaches genuinely disagree?
└── Which approaches should be deepened?

Phase 4: SYNTHESIZE (5 min)
├── Construct candidate answer from best elements
├── Test against success criteria
├── Identify remaining weaknesses
└── Document minority views
```

### When to Invoke Sophisticated Minds

**Triggers**:
1. **Novelty**: ORIENT stage finds no matching patterns (< 0.7 similarity)
2. **Uncertainty**: Multiple patterns match with similar confidence
3. **Stakes**: Task flagged as high-impact
4. **User Request**: Explicit `/minds deep` invocation
5. **Failure Loop**: Normal execution failed 2+ times

**Skip when**:
- Questions with clear, known answers
- Time-sensitive decisions
- Highly constrained problems where exploration space is small

---

## Piece 2: Workflow Execution (ISLE)

### The Iterative Self-Learning Engine

ISLE is a **6-stage execution loop** that handles the actual doing of work:

```
SENSE → ORIENT → DECIDE → ACT → REFLECT → ADAPT
```

| Stage | Purpose | Key Activities |
|-------|---------|----------------|
| **SENSE** | Perceive the problem space | Gather inputs, constraints, goals |
| **ORIENT** | Build mental model | Retrieve lessons, model the domain |
| **DECIDE** | Select approach | Generate candidates, evaluate, commit |
| **ACT** | Execute solution | Implement, run tools, produce artifacts |
| **REFLECT** | Evaluate outcomes | Compare results to expectations |
| **ADAPT** | Improve future cycles | Crystallize lessons, update behavior |

### Why This Loop?

| Alternative | Why Modified |
|-------------|--------------|
| OODA (4-stage) | Missing explicit reflection and adaptation |
| PDCA (4-stage) | Missing sensing and orientation |
| Simple loop | Too coarse; misses critical phases |

ISLE adds two AI-specific stages:
- **ADAPT**: Explicit behavioral update (not just observation)
- **Recursive self-application**: The engine can improve itself

### Self-Improvement: How ISLE Improves Itself

The engine treats its own operation as a problem domain:

**What can be improved:**
| Component | How Improved |
|-----------|--------------|
| **Lesson Store** | Track application success; decay unused |
| **Retrieval** | Learn from "lesson applied + succeeded" correlation |
| **Prompts** | Track variants → outcomes; promote winners |
| **Routing** | Beta distribution updates from task outcomes |
| **Convergence** | Calibrate thresholds from actual data |

**Safety boundaries:**
1. **Immutable Core** - Loop, safety checks, escalation paths cannot be modified
2. **Scope Limits** - Only lessons, prompts, parameters, weights
3. **Velocity Limits** - Max changes per time window
4. **Human Gates** - Critical changes require approval
5. **Observable Invariants** - Properties that must always hold

### Convergence: When to Stop Iterating

```python
# Hard stops (any one triggers halt)
budget_exhausted: bool        # Token/cost limit
timeout_reached: bool         # Wall-clock time
safety_violation: bool        # Harmful action detected

# Soft signals (weighted combination > 0.85)
goal_achieved: float          # Success criteria met
diminishing_returns: float    # Improvement rate declining
oscillation_detected: float   # Cycling between states
```

---

## Piece 3: Learning (Rich Learning Capture)

### The Core Insight

> **Learning is preserved reasoning, not recorded rules.**

The problem with thin learning like "when X, do Y":
- Can't evaluate if it applies to new context
- Can't improve on the suggestion
- Can't intelligently merge with other learnings
- Encourages blind rule-following → "false learning"

### What Makes Learning "Rich"

Every learning must capture:

1. **Causal Model** - WHY the observation implies a particular response
2. **Boundary Conditions** - WHEN this reasoning holds vs breaks down
3. **Alternatives Considered** - What was weighed and why rejected
4. **Confidence Basis** - What evidence supports this, and its strength

### Rich Learning Schema

```yaml
learning:
  trigger:
    observation: "What was noticed"
    context: "When/where noticed"

  reasoning:
    situation: "Prose description of what happened"
    causal_model: "WHY it happened - the mechanism"
    causal_chain: ["A led to", "B which caused", "C"]

  applicability:
    requires:
      - "Condition that must be true"
    invalidated_by:
      - "Condition that means this doesn't apply"
    uncertain_when:
      - "Need to investigate in this case"

  response:
    primary_action: "What to do"
    action_rationale: "Why this action addresses the cause"
    alternatives:
      - option: "Alternative approach"
        when_preferred: "Context where this is better"
        trade_offs: "What you give up"

  evidence:
    basis: "How we know this"
    occurrences: 3
    success_rate: 0.85
    scope: "validated"  # hypothesis/validated/established/canonical

  adaptation:
    guidance: "How to modify for different contexts"
    variations:
      - context_difference: "If X is different"
        adaptation: "Then adjust Y"
```

### Three-Tier Compression

| Tier | Purpose | Size |
|------|---------|------|
| **Index** | Fast retrieval | ~50 words: keywords, pattern, confidence |
| **Reasoning** | Application judgment | ~200 words: causal model, boundaries, trade-offs |
| **Full Context** | Deep understanding | Reference to source workflow |

### Avoiding False Learning

**False learning types:**
1. **Coincidental correlation** - Two things happened together but aren't causal
2. **Overfitted** - Works in original context, fails elsewhere
3. **Survivorship bias** - Remember successes, forget failures
4. **Context blindness** - Ignoring what made solution work

**Prevention:**
- Require causal explanation, not just observation
- Require explicit boundary conditions
- Track both successful and failed applications
- Require evidence before promoting

---

## How the Pieces Connect

### The Relationship

```
Sophisticated Minds is NOT separate from ISLE -
it IS the ORIENT and DECIDE stages when operating at full depth.

                Normal Mode              Sophisticated Minds Mode
────────────────────────────────────────────────────────────────
SENSE           Perceive input           Same
ORIENT          Quick pattern match      Full CRYSTALLIZE + DIVERGE
DECIDE          Select best-fit          Full CROSS-POLLINATE + SYNTHESIZE
ACT             Execute                  Same (but richer context)
REFLECT         Observe outcome          Same (but deeper analysis)
ADAPT           Update behavior          Same (but updates are richer)
```

### Where Learning Operates

**During ORIENT**: Retrieve relevant lessons to inform current decision
**During REFLECT**: Capture learnings from current execution

```
    ┌─────────────────────────────┐
    │   RICH LEARNING CAPTURE     │
    │   (Persistent Memory)       │
    └─────────────────────────────┘
              ▲           │
    WRITE     │           │   READ
    (REFLECT) │           │   (ORIENT)
              │           ▼
    SENSE → ORIENT → DECIDE → ACT → REFLECT → ADAPT
```

---

## Implementation Approach

### Relationship to Existing Orchestrator

**Recommended: Hybrid Architecture**

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    ISLE (Iterative Self-Learning Engine)                     │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────────┐    │
│  │                    Shared Components                                 │    │
│  │  - LessonStore + LessonCards                                         │    │
│  │  - Skill/Routing database                                            │    │
│  │  - Convergence detector                                              │    │
│  │  - Self-modification guard                                           │    │
│  └─────────────────────────────────────────────────────────────────────┘    │
│                             │                                                │
│           ┌─────────────────┼─────────────────┐                             │
│           ▼                 ▼                 ▼                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │   Orchestrator   │  │ Other Problem   │  │   Future        │             │
│  │   Adapter        │  │ Type Adapters   │  │   Adapters      │             │
│  │                  │  │                  │  │                  │             │
│  │  Maps ISLE to:   │  │  - Research     │  │  - Strategy     │             │
│  │  PLAN=SENSE+     │  │  - Creative     │  │  - Operations   │             │
│  │  EXECUTE=ACT     │  │                  │  │                  │             │
│  │  REVIEW+VERIFY=  │  │                  │  │                  │             │
│  │       REFLECT    │  │                  │  │                  │             │
│  │  LEARN=ADAPT     │  │                  │  │                  │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### Sophisticated Minds Implementation

**Entry point**: `minds deep "question"`

**Process**:
1. Creates session with config (time budget, cost budget, models)
2. Runs through phases (Crystallize → Diverge → Cross-Pollinate → Synthesize)
3. Persists state for resumability
4. Outputs structured markdown with reasoning trace

**Key features**:
- ~30 minute deep exploration
- 5+ models/approaches in parallel
- Progress display during execution
- Minority views documented
- Reasoning trace preserved

### Learning System Implementation

**Three-layer artifact model**:
1. **Episode**: Raw bounded unit from workflow
2. **CandidateLesson**: LLM-extracted, not yet approved
3. **LessonCard**: Approved, retrievable knowledge

**Lifecycle**: `draft → candidate → approved → embedded → archived`

**Never auto-merge** - Human review gate required

---

## The WHY Behind Key Decisions

### Why 6-stage ISLE loop?

Because action is the fundamental unit. Effective agents must:
1. Perceive before deciding (SENSE)
2. Orient based on context (ORIENT)
3. Commit to approach (DECIDE)
4. Execute (ACT)
5. Evaluate results (REFLECT)
6. Update behavior (ADAPT)

### Why Sophisticated Minds as a mode, not separate system?

Because deep thinking is expensive and not always needed. Making it a mode:
- Saves compute on routine tasks
- Focuses resources where they matter
- Allows graceful degradation under time pressure

### Why Rich Learning requires causal models?

Without understanding WHY something works:
- Can't evaluate if it applies to new context
- Can't adapt when context differs
- Can't improve on the approach
- Creates "false learning" that overfits

### Why hybrid structured/prose learning capture?

**Structured** enables: fast retrieval, filtering, automated checks
**Prose** enables: nuanced reasoning, "it depends", contextual judgment

Both are needed for learning that's both retrievable AND applicable.

---

## Dogfooding Observations

From this research process itself:

| Observation | Implication |
|-------------|-------------|
| The research itself followed the GPA pattern | Framework is self-applicable |
| Parallel model queries produced diverse insights | Fork-merge validated |
| Synthesis required explicit effort (not just concatenation) | Merge is the hard part |
| Without capturing reasoning, learnings are shallow | Rich capture is essential |
| Iteration revealed progressively deeper insights | Loops work |

---

## Next Steps

1. **Implement Sophisticated Minds MVP** - Basic session with framework execution
2. **Extend learning schema** - Add causal_model, boundary_conditions, alternatives
3. **Build learning crystallization pipeline** - Episode → CandidateLesson → LessonCard
4. **Create orchestrator adapter** - Map ISLE to existing workflow phases
5. **Add self-improvement tracking** - Measure lesson effectiveness over time

---

## Cost Tracking

| Research Phase | Experiments | Cost |
|----------------|-------------|------|
| Phase 1-3 | 14 | ~$1.82 |
| Phase 4 (Iterations 1-6) | 20 | ~$3.02 |
| Phase 5 (GPA synthesis) | 5 | ~$2.00 |
| Phase 5 (Dogfooding critique) | 5 | ~$1.50 |
| **Total** | **44** | **~$8.34** |

Budget remaining: ~$91.66

---

## Dogfooding Critique: GPA Applied to GPA

We applied the GPA framework to critique and improve itself. This section captures the process and findings.

### The Process

We ran Sophisticated Minds mode with 5 parallel approaches:
1. **First Principles** - What assumptions might be wrong?
2. **Inversion** - How could this fail spectacularly?
3. **Devil's Advocate** - Argue against every claim
4. **Practitioner Perspective** - What happens when real people use this?
5. **Missing Pieces** - What categories are entirely absent?

### Critical Weaknesses Identified

#### Weakness 1: No Empirical Validation
**Every critique mentioned this.**

The GPA claims:
- 6-stage ISLE is better than 4-stage PDCA
- Sophisticated Minds produces better outcomes
- Rich Learning Capture prevents false learning

**Evidence provided: Zero.** No baselines, no A/B tests, no measurements.

**WHY this matters:** Without validation, we don't know if the complexity buys anything. It could all be "sophistication theater."

**FIX:** Before implementing fully:
1. Define success metrics (pass@1, cost-per-success, error-repeat-rate)
2. Establish baseline (single-shot, simple loop)
3. Compare GPA vs baseline on 20+ real tasks
4. Only keep components that demonstrably improve metrics

---

#### Weakness 2: Over-Engineering Without Proven ROI
**Multiple critiques converged here.**

Current complexity:
- 6 stages in ISLE (vs 3-4 in proven loops)
- 4 types of memory (lesson cards, causal models, transactive, skill profiles)
- 4 phases in Sophisticated Minds
- 3-tier learning compression
- Rich schema with causal models, boundary conditions, alternatives, evidence

**The practitioner perspective:** "7 JSON validations to pass a single task"

**WHY this matters:** Complexity has costs - cognitive load, maintenance burden, failure surface area. Without ROI proof, simpler is better.

**FIX:** Start with Minimal Viable GPA:
```
MVP Loop: SENSE → DECIDE → ACT → REFLECT
MVP Learning: Single format (LEARNINGS.md OR Supabase, not both)
MVP Thinking: Fast mode default, deep mode only when fast fails 2+ times
```
Add complexity only when MVP proves insufficient.

---

#### Weakness 3: Missing Feedback Loop
**The most damaging finding.**

The critiques revealed:
- "ADAPT never actually happens" (Practitioner)
- "Learnings don't inform workflow updates" (Practitioner)
- "No measurement of learning effectiveness" (First Principles)
- "97/100 runs skip reviews after initial use" (Telemetry)

**WHY this matters:** A learning system that doesn't change behavior isn't learning - it's just logging.

**FIX:** Close the loop:
1. Every learning must have a **measurable expected outcome**
2. Track whether that outcome improves after learning is applied
3. Auto-decay learnings that don't demonstrate value within 30 days
4. Make ADAPT mandatory, not optional

---

#### Weakness 4: False Learning Risk
**Causal models are narratives, not truth.**

The critiques revealed:
- "LLMs generate plausible narratives, you store them, entropy accumulates" (Devil's Advocate)
- "Boundary conditions are imaginary until violated" (Devil's Advocate)
- "Coincidental correlation → false causation" (Inversion)

**WHY this matters:** Confident, well-documented wrong learnings are worse than no learnings - they actively mislead.

**FIX:** Evidence requirements:
1. **Hypothesis** (1 occurrence): Store as observation, not learning
2. **Candidate** (2-3 occurrences): May be pattern, needs validation
3. **Validated** (5+ occurrences with measured improvement): Can be trusted
4. Auto-expire hypotheses after 30 days if not validated

---

#### Weakness 5: Single-Agent Assumption
**GPA ignores collaboration and human integration.**

Missing entirely:
- Multi-agent coordination
- Human approval gates
- Stakeholder communication
- Conflict resolution between agents/humans

**WHY this matters:** Real workflows involve multiple agents and humans. A framework that ignores this is incomplete.

**FIX:** Add three layers to GPA v2:
1. **Collaboration Layer** - Agent-to-agent handoffs, conflict resolution
2. **Human Integration Layer** - Approval gates, escalation paths, override
3. **Communication Layer** - Status narratives, risk framing, expectation management

---

#### Weakness 6: Resource Blindness
**No awareness of time, tokens, or money.**

The critiques revealed:
- "Sophisticated Minds tax: 30 min compute, rarely invoked" (Inversion)
- "Token waste masquerading as cognition" (Devil's Advocate)
- "30-50% overhead on small tasks" (Practitioner)

**WHY this matters:** Deep thinking is expensive. Applying it to trivial tasks is waste.

**FIX:** Budget-aware execution:
```python
def decide_depth(task, budget):
    if budget.time_remaining < 5_minutes:
        return "fast"  # Pattern match only
    elif budget.time_remaining < 30_minutes:
        return "moderate"  # Quick exploration
    elif task.stakes == "high" or task.novelty > 0.7:
        return "deep"  # Full Sophisticated Minds
    else:
        return "fast"  # Default to efficient
```

---

### Revised GPA Architecture (v2)

Based on the dogfooding critique:

```
┌─────────────────────────────────────────────────────────────────────────────────┐
│                     GENERAL PERSON ALGORITHM v2                                  │
├─────────────────────────────────────────────────────────────────────────────────┤
│                                                                                  │
│  ┌─────────────────────────────────────────────────────────────────────────────┐│
│  │ LEARNING (Simplified)                                                        ││
│  │ • Single format (not 4 types)                                               ││
│  │ • Evidence tiers (hypothesis → candidate → validated)                       ││
│  │ • Auto-decay (30 days if no validation)                                     ││
│  │ • Effectiveness tracking (did it improve outcomes?)                         ││
│  └─────────────────────────────────────────────────────────────────────────────┘│
│                              ▲           │                                       │
│                              │           ▼                                       │
│  ┌─────────────────────────────────────────────────────────────────────────────┐│
│  │ EXECUTION (MVP Loop)                                                         ││
│  │                                                                              ││
│  │  ┌────────┐    ┌────────┐    ┌────────┐    ┌────────┐                      ││
│  │  │ SENSE  │───►│ DECIDE │───►│  ACT   │───►│REFLECT │                      ││
│  │  └────────┘    └───┬────┘    └────────┘    └────────┘                      ││
│  │                    │                                                         ││
│  │         [Budget check + stakes check]                                       ││
│  │                    │                                                         ││
│  │         ┌─────────┴─────────┐                                               ││
│  │         ▼                   ▼                                               ││
│  │    [FAST: pattern    [DEEP: Sophisticated                                   ││
│  │     match only]       Minds if budget allows]                               ││
│  │                                                                              ││
│  └─────────────────────────────────────────────────────────────────────────────┘│
│                              ▲           │                                       │
│                              │           ▼                                       │
│  ┌─────────────────────────────────────────────────────────────────────────────┐│
│  │ CONTEXT (New in v2)                                                          ││
│  │ • Resource budgets (time, tokens, cost)                                     ││
│  │ • Human integration (approval gates, escalation)                            ││
│  │ • Multi-agent coordination (handoffs, conflicts)                            ││
│  │ • Interruption/resume (checkpoints, context switch)                         ││
│  └─────────────────────────────────────────────────────────────────────────────┘│
│                                                                                  │
└─────────────────────────────────────────────────────────────────────────────────┘
```

### Key Changes from v1 to v2

| Aspect | GPA v1 | GPA v2 | Reasoning |
|--------|--------|--------|-----------|
| Loop stages | 6 (SENSE→ORIENT→DECIDE→ACT→REFLECT→ADAPT) | 4 (SENSE→DECIDE→ACT→REFLECT) | Simpler; prove need before adding |
| Memory types | 4 (lessons, causal, transactive, skills) | 1 (unified format) | Reduce maintenance burden |
| Default mode | Full exploration | Fast pattern-match | Resource efficient; escalate only when needed |
| Learning validation | Store with confidence | Evidence tiers + auto-decay | Prevents false learning accumulation |
| Human integration | Absent | First-class citizen | Required for real workflows |
| Resource awareness | Convergence detection only | Proactive budgeting | Prevents wasteful deep thinking |

### Dogfooding Meta-Learning

**What this process taught us:**

1. **The framework IS self-applicable** - We used GPA to critique GPA
2. **Parallel critiques find different things** - 5 approaches, 6 major weaknesses
3. **Synthesis is the hard part** - Convergence on improvements took effort
4. **The critiques were brutal but useful** - "Sophistication theater" stings but is valid

**The irony:** By applying GPA to itself, we discovered GPA was over-engineered. The framework's own methodology proved the framework needs simplification.

**Rich Learning from this process:**

```yaml
learning:
  trigger: "Designing a complex framework with multiple components"

  causal_model: |
    Researchers naturally add features that COULD be useful.
    Each feature seems reasonable in isolation.
    Combined, the overhead exceeds the benefit.
    Without baseline comparison, this isn't detected.

  boundary_conditions:
    applies_when:
      - "Building from research/theory, not iteration"
      - "No empirical validation loop"
      - "Multiple contributors with different concerns"
    does_not_apply_when:
      - "Iterating based on measured failure modes"
      - "Adding features only when simpler version fails"

  response:
    action: "Start with Minimal Viable X, add complexity only when MVP fails"
    why: "Complexity has invisible costs; prove need before paying"

  evidence:
    basis: "GPA dogfooding revealed 6 major weaknesses from over-engineering"
    occurrences: 1
    scope: "hypothesis"  # Needs more validation
```

---

## Next Steps (Updated)

### Immediate (Validate Before Building)
1. **Define metrics** - Pass@1, cost-per-success, error-repeat-rate
2. **Establish baseline** - Single-shot performance on 20 tasks
3. **Test MVP loop** - 4-stage vs 6-stage on same tasks
4. **Measure Sophisticated Minds ROI** - Does 30 min thinking beat 2 min pattern-match?

### Near-term (Build What's Proven)
1. **Implement MVP loop** - SENSE→DECIDE→ACT→REFLECT
2. **Unified learning format** - One schema, not four
3. **Evidence tiers** - hypothesis/candidate/validated with auto-decay
4. **Budget-aware execution** - Fast/moderate/deep based on constraints

### Future (Only If Validated)
1. **Add ORIENT and ADAPT** - If 4-stage proves insufficient
2. **Sophisticated Minds** - If fast mode has >20% failure rate
3. **Rich causal models** - If simple learnings overfit
4. **Multi-agent coordination** - When parallel execution is needed

---

*Research conducted 2026-01-22. Updated with dogfooding critique and GPA v2 architecture.*
